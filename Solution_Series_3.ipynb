{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtTQTltIxKDS"
   },
   "source": [
    "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
    "\n",
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 2: طبقه بندی تصاویر Cifar10 با شبکه های کانولوشنالی روی googleColab</div></center></h1>\n",
    "\n",
    "[![Run in Google Colab](https://github.com/Alireza-Akhavan/deeplearning-tensorflow2-notebooks/blob/master/homework/images/colab.png?raw=1)](https://colab.research.google.com/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/homework/ex2-conv-cifar10-in-colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lTAY4l_xKDV"
   },
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">صورت مساله</div>\n",
    "\n",
    "\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "با شبکه های کانولوشنالی آشنا شدیم<br>\n",
    "توصیه می‌شود حتما بعد از تمرین اول این تمرین را حل کنید و قبل از این تمرین نوت بوک زیر را  مرور کنید:\n",
    "</div>\n",
    "\n",
    "[06_ConvolutionalNeuralNetwork-Hoda-Keras.ipynb ](https://nbviewer.jupyter.org/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/06_ConvolutionalNeuralNetwork-Hoda-Keras.ipynb)\n",
    "\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "در این تمرین از مجموعه داده تصویری cifar10 استفاده خواهیم کرد.\n",
    "<br>\n",
    "خیلی از اوقات ممکنه دسترسی به GPU نداشته باشیم. حخوشبختانه سرویس های آنلاین و رایگانی هستند که توان محاسباتی رایگان در اختیارمان میگذراند. در این تمرین از شما خواسته شده که این نوت بوک را در گوگل کولب اجرا کنید.\n",
    "<br>\n",
    " قبلا در مورد گوگل کولب دو پست آموزشی نوشته شده است که در صورت تمایل به کسب اطلاعات بیشتر میتوانید بخوانید.\n",
    "    اما برای اجرا این تمرین نیازی به این جزئیات نخواهید داشت.\n",
    "</div>\n",
    "\n",
    "[آشنایی با سرویس ابری Google Colab ](http://blog.class.vision/1397/02/google-colab/)\n",
    "\n",
    "[اتصال مستقیم سرویس کولب (Google Colab) به درایو (Google Drive) از طریق فایل سیستم FUSE ](http://blog.class.vision/1397/04/%D8%A7%D8%AA%D8%B5%D8%A7%D9%84-%D9%85%D8%B3%D8%AA%D9%82%DB%8C%D9%85-%D8%B3%D8%B1%D9%88%DB%8C%D8%B3-%DA%A9%D9%88%D9%84%D8%A8-google-colab-%D8%A8%D9%87-%D8%AF%D8%B1%D8%A7%DB%8C%D9%88-google-drive/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bTucehCxKDW"
   },
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">لود کتابخانه های مورد نیاز </div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "کتابخانه های مورد نیاز این تمرین لود شده اند\n",
    "<br>\n",
    "در صورت نیاز میتوانید کتابخانه های بیشتری لود کنید:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "17-uBVEXxKDW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 11:55:21.289564: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-22 11:55:21.290528: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 11:55:21.342696: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 11:55:21.595545: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 11:55:22.281887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.datasets import cifar10\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH3Eqi_ZxKDY"
   },
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">مجموعه داده ی Cifar10 </div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "<br>\n",
    "این مجموعه داده تصاویر رنگی در اندازه ی 32 در 32 و در 10 کلاس مختلف شامل ماشین، کامیون، اسب و ... است که در چارچوب کراس موجود است و از همان استفاده میکنیم.\n",
    "<br>\n",
    "اطلاعات بیشتر در مورد این مجموعه داده را از سایت این مجموعه داده میتوانید مطالعه کنید:\n",
    "<br>\n",
    "</div>\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jG_YJGsuxKDZ",
    "outputId": "21e60490-d895-4cbb-9d7a-d82d222e826a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train_org), (x_test, y_test_org) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kopGsxV9xKDZ"
   },
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">نگاهی به مجموعه داده بیندازیم...</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "در زیر تصویری که در اندیس 7-ام این مجموعه داده قرار دارد را مشاهده می‌کنیم. این شماره را را به دلخوه عوض کنید و چند تصویر دیگر این مجموعه داده را ببینید.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ut-vmxyoxKDa",
    "outputId": "2505c689-27bb-4ef8-ad07-915268e273e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7479783e0d50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XHODfNaxKDb"
   },
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 1:</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "ماتریس های تصویر را تبدیل به نوع داده ای float32 کنید و مقادیر پیکسل ها را نرمال کنید و بین 0 و 1 بیاورید.\n",
    "<br>\n",
    "<b>راهنمایی: </b>\n",
    "شما باید متد astype را صدا بزنید و در نهایت مقادیر پیکسل ها را تقسیم بر 255 کنید.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4IQWltyYxKDc"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "UPnkoXxsXSiC"
   },
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYDRmsp0xKDd"
   },
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 2:</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "همان طور که میبینید لیبل ها از نوع عددی هستند. آن ها را تبدیل به فرمت one-hot کنید.<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viVyawXHxKDd"
   },
   "source": [
    "<hr>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "تعدادی از لیبل ها قبل از تبدیل به فرمت one-hot:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a_ZIR9XxKDd",
    "outputId": "5be4cb4c-43da-466e-ad1a-d5a734a53917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [7],\n",
       "       [8],\n",
       "       [3]], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_org[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "p3TpqdhaYITv"
   },
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "y_train = utils.to_categorical(y_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "kucirGSeXu9i"
   },
   "outputs": [],
   "source": [
    "y_test = utils.to_categorical(y_test_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nIiL7hmxKDe"
   },
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "تعدادی از لیبل ها بعد از تبدیل به فرمت one-hot:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JbVvamJxKDe",
    "outputId": "a2de2956-8c25-4bf9-8974-dd607d6f1104"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jippik5ixKDe"
   },
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 3:</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "یک شبکه کانولوشنالی با معماری زیر بسازید:\n",
    "<ul>\n",
    "    <li>\n",
    "    یک لایه کانولوشنی با32 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
    "    </li>\n",
    "    <li>\n",
    "    لایه ی pooling با pool_size=(2,2)\n",
    "    </li>\n",
    "    <li>\n",
    "    یک لایه کانولوشنی با32 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
    "    </li>\n",
    "    <li>\n",
    "    لایه ی pooling با pool_size=(2,2)\n",
    "    </li>\n",
    "    <li>\n",
    "    یک لایه کانولوشنی با64 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
    "    </li>\n",
    "    <li>\n",
    "    لایه ی pooling با pool_size=(2,2)\n",
    "    </li>\n",
    "    <li>\n",
    "    استفاده از لایه ی Flatten() . به نظرتون چرا؟\n",
    "    </li>    \n",
    "    <li>\n",
    "    یک لایه Dropout با ترخ 0.5.\n",
    "    </li>\n",
    "    <li>\n",
    "    یک لایه softmax برای احتمالات خروجی. به نظرتون این لایه چند نوران میخواهد؟\n",
    "    </li>    \n",
    "\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2DKJY9sxKDf"
   },
   "outputs": [],
   "source": [
    "model_cifar10 = Sequential()\n",
    "model_cifar10.add(Conv2D(32 , (3 , 3 ) , activation = 'relu' , input_shape = (32, 32 , 3)))\n",
    "model_cifar10.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model_cifar10.add(Conv2D(32 , (3 , 3 ) , activation = 'relu'))\n",
    "model_cifar10.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cifar10.add(Conv2D(64 , (3 , 3 ) , activation = 'relu'))\n",
    "model_cifar10.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cifar10.add(Flatten())\n",
    "model_cifar10.add(Dropout(rate = 0.5))\n",
    "model_cifar10.add(Dense(10 , activation = 'softmax' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OQ_Jxh1xKDf"
   },
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 4:</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "مدل را کامپایل کنید و به عنوان optimizer متغیر opt_rms به تابع ارسال کنید. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOZvbiY2xKDf"
   },
   "outputs": [],
   "source": [
    "opt_rms = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model_cifar10.compile(optimizer = opt_rms , loss =\"categorical_crossentropy\", metrics = ['acc'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx6vIkg8xKDf"
   },
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 5:</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "با فراخوانی متد fit روی مدل آن را آموزش بدهید. برای سادگی25 ایپاک با سایز بچ 64 بزنید.\n",
    "    <br>\n",
    " به عنوان دیتای validation نیز x_test و y_test را ارسال کنید که در هر سری کارایی روی داده های تست اعلام شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viXQ1U1ms5JO",
    "outputId": "bd7c4234-bea4-4555-c06e-79b2c897941f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - acc: 0.2430 - loss: 2.0233 - val_acc: 0.4512 - val_loss: 1.5307\n",
      "Epoch 2/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - acc: 0.4218 - loss: 1.5849 - val_acc: 0.4800 - val_loss: 1.4219\n",
      "Epoch 3/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - acc: 0.4867 - loss: 1.4391 - val_acc: 0.4814 - val_loss: 1.4639\n",
      "Epoch 4/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.5236 - loss: 1.3356 - val_acc: 0.5130 - val_loss: 1.4131\n",
      "Epoch 5/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.5548 - loss: 1.2564 - val_acc: 0.5804 - val_loss: 1.1739\n",
      "Epoch 6/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.5745 - loss: 1.2049 - val_acc: 0.6058 - val_loss: 1.1196\n",
      "Epoch 7/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.5874 - loss: 1.1652 - val_acc: 0.5563 - val_loss: 1.2311\n",
      "Epoch 8/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - acc: 0.6013 - loss: 1.1340 - val_acc: 0.6304 - val_loss: 1.0450\n",
      "Epoch 9/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - acc: 0.6131 - loss: 1.1039 - val_acc: 0.6399 - val_loss: 1.0115\n",
      "Epoch 10/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6291 - loss: 1.0669 - val_acc: 0.6302 - val_loss: 1.0547\n",
      "Epoch 11/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - acc: 0.6341 - loss: 1.0526 - val_acc: 0.6594 - val_loss: 0.9816\n",
      "Epoch 12/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - acc: 0.6475 - loss: 1.0171 - val_acc: 0.6593 - val_loss: 0.9786\n",
      "Epoch 13/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6449 - loss: 1.0000 - val_acc: 0.6453 - val_loss: 1.0099\n",
      "Epoch 14/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6541 - loss: 0.9834 - val_acc: 0.6661 - val_loss: 0.9777\n",
      "Epoch 15/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - acc: 0.6598 - loss: 0.9747 - val_acc: 0.6705 - val_loss: 0.9641\n",
      "Epoch 16/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6621 - loss: 0.9614 - val_acc: 0.6280 - val_loss: 1.1171\n",
      "Epoch 17/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6636 - loss: 0.9564 - val_acc: 0.6645 - val_loss: 0.9880\n",
      "Epoch 18/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - acc: 0.6706 - loss: 0.9346 - val_acc: 0.6872 - val_loss: 0.8971\n",
      "Epoch 19/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - acc: 0.6728 - loss: 0.9410 - val_acc: 0.6083 - val_loss: 1.1061\n",
      "Epoch 20/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6748 - loss: 0.9262 - val_acc: 0.6783 - val_loss: 0.9681\n",
      "Epoch 21/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6831 - loss: 0.9136 - val_acc: 0.7061 - val_loss: 0.8594\n",
      "Epoch 22/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - acc: 0.6870 - loss: 0.8956 - val_acc: 0.6903 - val_loss: 0.8945\n",
      "Epoch 23/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - acc: 0.6847 - loss: 0.9012 - val_acc: 0.6810 - val_loss: 0.9447\n",
      "Epoch 24/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - acc: 0.6856 - loss: 0.8915 - val_acc: 0.6917 - val_loss: 0.8982\n",
      "Epoch 25/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - acc: 0.6973 - loss: 0.8771 - val_acc: 0.6684 - val_loss: 0.9656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7479387af110>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cifar10.fit(x_train, y_train, batch_size= 64, epochs = 25 , validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hp2aR56tFLA9",
    "outputId": "15ecd26b-fa81-402f-dce8-fb36daa9291d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6685 - loss: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9656073451042175, 0.66839998960495]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cifar10.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "banK-69NxKDg"
   },
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 6:</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "شبکه و هایپرپارامترهای این شبکه را به هر نحوی دوست دارید تغییر دهید تا دقت روی دادگان تست را به حداکثر برسانید.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ttGXw4EzmkNz"
   },
   "outputs": [],
   "source": [
    "#Changing Layers to Boost Model Accuracy\n",
    "model_cifar10_boosted = Sequential()\n",
    "model_cifar10_boosted.add(Conv2D(32 , (3 , 3 ) , activation = 'relu' , padding = \"same\" , input_shape = (32, 32 , 3)))\n",
    "model_cifar10_boosted.add(Conv2D(32 , (3 , 3 ) , activation = 'relu' , padding = \"same\"))\n",
    "model_cifar10_boosted.add(MaxPooling2D(pool_size = (2,2) , strides= (2,2)))\n",
    "model_cifar10_boosted.add(Conv2D(64 , (3 , 3 ) , activation = 'relu' , padding = \"same\"))\n",
    "model_cifar10_boosted.add(MaxPooling2D(pool_size = (2,2) , strides= (2,2)))\n",
    "model_cifar10_boosted.add(Flatten())\n",
    "model_cifar10_boosted.add(Dropout(0.5))\n",
    "model_cifar10_boosted.add(Dense(10 , activation = 'softmax' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "C3hUDADeFLA-"
   },
   "outputs": [],
   "source": [
    "model_cifar10_boosted.compile(optimizer = \"Adam\" , loss =\"categorical_crossentropy\", metrics = ['acc'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrpzwK6DFLA-",
    "outputId": "e574f9f8-7c0e-4750-cf2e-ed3ac4623457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 1.4944 - acc: 0.4640 - val_loss: 1.1314 - val_acc: 0.6038\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1072 - acc: 0.6117 - val_loss: 0.9579 - val_acc: 0.6708\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9798 - acc: 0.6618 - val_loss: 0.9237 - val_acc: 0.6839\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9045 - acc: 0.6857 - val_loss: 0.8177 - val_acc: 0.7197\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8549 - acc: 0.7019 - val_loss: 0.8091 - val_acc: 0.7223\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8154 - acc: 0.7162 - val_loss: 0.7842 - val_acc: 0.7357\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7852 - acc: 0.7277 - val_loss: 0.7502 - val_acc: 0.7386\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7584 - acc: 0.7373 - val_loss: 0.7608 - val_acc: 0.7411\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7406 - acc: 0.7426 - val_loss: 0.7329 - val_acc: 0.7483\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7185 - acc: 0.7506 - val_loss: 0.7597 - val_acc: 0.7355\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7021 - acc: 0.7564 - val_loss: 0.7230 - val_acc: 0.7506\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6952 - acc: 0.7566 - val_loss: 0.7208 - val_acc: 0.7513\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6752 - acc: 0.7645 - val_loss: 0.7192 - val_acc: 0.7518\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6629 - acc: 0.7698 - val_loss: 0.7349 - val_acc: 0.7453\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6535 - acc: 0.7709 - val_loss: 0.7108 - val_acc: 0.7564\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6475 - acc: 0.7739 - val_loss: 0.7081 - val_acc: 0.7571\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6348 - acc: 0.7764 - val_loss: 0.7187 - val_acc: 0.7564\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6245 - acc: 0.7821 - val_loss: 0.7208 - val_acc: 0.7543\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6236 - acc: 0.7823 - val_loss: 0.7049 - val_acc: 0.7600\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6146 - acc: 0.7841 - val_loss: 0.7061 - val_acc: 0.7563\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6036 - acc: 0.7868 - val_loss: 0.6929 - val_acc: 0.7658\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6047 - acc: 0.7886 - val_loss: 0.7077 - val_acc: 0.7596\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5939 - acc: 0.7911 - val_loss: 0.7163 - val_acc: 0.7585\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5927 - acc: 0.7917 - val_loss: 0.7011 - val_acc: 0.7623\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5859 - acc: 0.7945 - val_loss: 0.6874 - val_acc: 0.7694\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5790 - acc: 0.7951 - val_loss: 0.6958 - val_acc: 0.7634\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5786 - acc: 0.7973 - val_loss: 0.7043 - val_acc: 0.7601\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5695 - acc: 0.7995 - val_loss: 0.7048 - val_acc: 0.7587\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5684 - acc: 0.7996 - val_loss: 0.6905 - val_acc: 0.7643\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5600 - acc: 0.8023 - val_loss: 0.7077 - val_acc: 0.7646\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5559 - acc: 0.8045 - val_loss: 0.7055 - val_acc: 0.7643\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5542 - acc: 0.8048 - val_loss: 0.7189 - val_acc: 0.7633\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5569 - acc: 0.8041 - val_loss: 0.6980 - val_acc: 0.7627\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5460 - acc: 0.8070 - val_loss: 0.7056 - val_acc: 0.7671\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5454 - acc: 0.8074 - val_loss: 0.7159 - val_acc: 0.7609\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5465 - acc: 0.8072 - val_loss: 0.7218 - val_acc: 0.7641\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5438 - acc: 0.8077 - val_loss: 0.7215 - val_acc: 0.7638\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5342 - acc: 0.8115 - val_loss: 0.7286 - val_acc: 0.7550\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5345 - acc: 0.8102 - val_loss: 0.7286 - val_acc: 0.7618\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5365 - acc: 0.8093 - val_loss: 0.6988 - val_acc: 0.7633\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5292 - acc: 0.8112 - val_loss: 0.7448 - val_acc: 0.7619\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5311 - acc: 0.8116 - val_loss: 0.7247 - val_acc: 0.7618\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5268 - acc: 0.8131 - val_loss: 0.7842 - val_acc: 0.7530\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5276 - acc: 0.8142 - val_loss: 0.7038 - val_acc: 0.7603\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5211 - acc: 0.8149 - val_loss: 0.7498 - val_acc: 0.7544\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5174 - acc: 0.8165 - val_loss: 0.7202 - val_acc: 0.7612\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5244 - acc: 0.8147 - val_loss: 0.7356 - val_acc: 0.7573\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5124 - acc: 0.8165 - val_loss: 0.7264 - val_acc: 0.7642\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5186 - acc: 0.8176 - val_loss: 0.7605 - val_acc: 0.7576\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5146 - acc: 0.8189 - val_loss: 0.7346 - val_acc: 0.7585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7982b30eda50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cifar10_boosted.fit(x_train, y_train, batch_size= 32, epochs = 50 , validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NVFqiVAFLA-",
    "outputId": "d9e40acf-9733-43f4-a3a5-90e82ca039be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7346 - acc: 0.7585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7345794439315796, 0.7584999799728394]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cifar10_boosted.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usOf5h3ExKDg"
   },
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 3: طبقه بندی تصاویر Fashion MNIST</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIoaEbRCmkNz",
    "outputId": "a1d3859e-fcfb-48b8-8a93-dce92682faaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Loading Dataset from keras repository\n",
    "from tensorflow import keras\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "#split Dataset into train and test\n",
    "(train_images, train_labels_org), (test_images, test_labels_org) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "z5cL3CQimkNz"
   },
   "outputs": [],
   "source": [
    "#Normalizing image data inorder to boost the accuracy of model\n",
    "train_images = train_images.astype(\"float32\")\n",
    "test_images = test_images.astype(\"float32\")\n",
    "train_images /= 255\n",
    "test_images /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "3xJC_2izoqam"
   },
   "outputs": [],
   "source": [
    "#Transforming labels to one-hot encoding inorder to be interpretable by softmax activation function\n",
    "from keras import utils\n",
    "train_labels = utils.to_categorical(train_labels_org)\n",
    "test_labels = utils.to_categorical(test_labels_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "mcnHJcLLo6aG"
   },
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "model_fmn = Sequential()\n",
    "model_fmn.add(Conv2D(8, (3,3), activation= 'relu', padding = \"same\", input_shape = (28,28,1)))\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Conv2D(16, (3,3), activation= 'relu' , padding = \"same\"))\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Conv2D(32, (3,3), activation= 'relu' , padding = \"same\"))\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Conv2D(64, (3,3), activation= 'relu' , padding = \"same\"))\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Flatten())\n",
    "model_fmn.add(Dropout(0.5))\n",
    "model_fmn.add(Dense(10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "9CgrWpd3sO6a"
   },
   "outputs": [],
   "source": [
    "model_fmn.compile(optimizer = \"Adam\", loss =\"categorical_crossentropy\", metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qdfsb0d-sO9Z",
    "outputId": "f5ea8dfa-83e1-4cce-df7c-5e5d7b4ce5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.7098 - acc: 0.7411\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4626 - acc: 0.8334\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4045 - acc: 0.8564\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3738 - acc: 0.8655\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3524 - acc: 0.8722\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3355 - acc: 0.8786\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3218 - acc: 0.8851\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3128 - acc: 0.8873\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3039 - acc: 0.8894\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2957 - acc: 0.8927\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2913 - acc: 0.8952\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2841 - acc: 0.8965\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2765 - acc: 0.8990\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2718 - acc: 0.9017\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2672 - acc: 0.9034\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2626 - acc: 0.9031\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2567 - acc: 0.9072\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2565 - acc: 0.9071\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2513 - acc: 0.9067\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2491 - acc: 0.9090\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2449 - acc: 0.9090\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2436 - acc: 0.9095\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2360 - acc: 0.9131\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2375 - acc: 0.9135\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2346 - acc: 0.9123\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2344 - acc: 0.9135\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2293 - acc: 0.9146\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2267 - acc: 0.9150\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2256 - acc: 0.9161\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2258 - acc: 0.9152\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2212 - acc: 0.9172\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2192 - acc: 0.9170\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2178 - acc: 0.9187\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2190 - acc: 0.9175\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2154 - acc: 0.9187\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2119 - acc: 0.9196\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2120 - acc: 0.9204\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2126 - acc: 0.9200\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2067 - acc: 0.9219\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2084 - acc: 0.9218\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2067 - acc: 0.9215\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2049 - acc: 0.9230\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2040 - acc: 0.9228\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2031 - acc: 0.9225\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2007 - acc: 0.9233\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2027 - acc: 0.9226\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1991 - acc: 0.9233\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1996 - acc: 0.9238\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1990 - acc: 0.9240\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1977 - acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7982b2ed5e40>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fmn.fit(train_images, train_labels,  batch_size=32 ,  epochs= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcPlhrIctvut",
    "outputId": "a6b94ee3-512e-44cd-abb6-a17409f7ef43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2865 - acc: 0.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28650936484336853, 0.9050999879837036]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of the Model\n",
    "model_fmn.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzF4dD-tmkN0"
   },
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 4: Bachnorm </div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "_k0nyuttmkN0"
   },
   "outputs": [],
   "source": [
    "#Adding Batchnorm Layer to the Model\n",
    "model_fmn = Sequential()\n",
    "model_fmn.add(Conv2D(8, (3,3), activation= 'relu', padding = \"same\", input_shape = (28,28,1)))\n",
    "model_fmn.add(BatchNormalization())\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Conv2D(16, (3,3), activation= 'relu' , padding = \"same\"))\n",
    "model_fmn.add(BatchNormalization())\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Conv2D(32, (3,3), activation= 'relu' , padding = \"same\"))\n",
    "model_fmn.add(BatchNormalization())\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Conv2D(64, (3,3), activation= 'relu' , padding = \"same\"))\n",
    "model_fmn.add(BatchNormalization())\n",
    "model_fmn.add(MaxPooling2D(2,2))\n",
    "model_fmn.add(Flatten())\n",
    "model_fmn.add(Dropout(0.5))\n",
    "model_fmn.add(Dense(10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "SOyb8vznXJZC"
   },
   "outputs": [],
   "source": [
    "model_fmn.compile(optimizer = \"Adam\", loss =\"categorical_crossentropy\", metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgDCjXdfXJjh",
    "outputId": "d2037bc5-a1c8-4aff-b075-37cef11131fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 13s 6ms/step - loss: 0.5892 - acc: 0.7957\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3816 - acc: 0.8635\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3334 - acc: 0.8799\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3048 - acc: 0.8909\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2857 - acc: 0.8972\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2726 - acc: 0.9013\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2593 - acc: 0.9067\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2530 - acc: 0.9094\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2425 - acc: 0.9116\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2385 - acc: 0.9140\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2297 - acc: 0.9174\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2244 - acc: 0.9195\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2207 - acc: 0.9196\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2152 - acc: 0.9208\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2145 - acc: 0.9226\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2079 - acc: 0.9243\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2035 - acc: 0.9271\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1995 - acc: 0.9276\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1983 - acc: 0.9276\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1953 - acc: 0.9289\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1918 - acc: 0.9297\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1900 - acc: 0.9302\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1856 - acc: 0.9326\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1855 - acc: 0.9320\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1830 - acc: 0.9334\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1789 - acc: 0.9349\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1795 - acc: 0.9348\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1740 - acc: 0.9362\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1747 - acc: 0.9362\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1733 - acc: 0.9357\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1705 - acc: 0.9389\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1693 - acc: 0.9382\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1673 - acc: 0.9384\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1663 - acc: 0.9388\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1638 - acc: 0.9402\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1657 - acc: 0.9396\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1608 - acc: 0.9399\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1610 - acc: 0.9410\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1588 - acc: 0.9422\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1574 - acc: 0.9421\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1557 - acc: 0.9430\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1565 - acc: 0.9423\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1543 - acc: 0.9421\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1520 - acc: 0.9440\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1496 - acc: 0.9440\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1515 - acc: 0.9438\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1490 - acc: 0.9452\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1488 - acc: 0.9449\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1457 - acc: 0.9466\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1468 - acc: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x79822397cfa0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fmn.fit(train_images, train_labels,  batch_size=32 ,  epochs= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHCcYTrdmkN0",
    "outputId": "6a981202-0776-458f-aaad-74c5e4dc9666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2747 - acc: 0.9132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27470991015434265, 0.9132000207901001]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of the Model\n",
    "model_fmn.evaluate(test_images , test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDt5TjMOmkN0"
   },
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 5: GAP </div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71KvGT3WmkN0",
    "outputId": "851179f6-03ae-4b8b-b400-9be5a50c7da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Loading Data set\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train_org), (x_test, y_test_org) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8_gV4vyq4Kd",
    "outputId": "5e5d9d9d-a92e-459f-8f8b-65b081a426c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_32 = x_train.reshape(-1,28,28,1)\n",
    "x_test_32 = x_test.reshape(-1,28,28,1)\n",
    "x_train_32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PlvNbzWQmkN0"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train_org)\n",
    "y_test = keras.utils.to_categorical(y_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRiNfoJLahc5"
   },
   "outputs": [],
   "source": [
    "from Model_creation import model_creation\n",
    "model = model_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjpU179LG8HK"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam' , loss = \"categorical_crossentropy\" , metrics = [\"acc\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmKGARToG8KE",
    "outputId": "9eb1ee27-5f56-4b0d-b1f1-6a6d18d9a172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 13s 4ms/step - loss: 0.4512 - acc: 0.8548\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1481 - acc: 0.9582\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1013 - acc: 0.9719\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0783 - acc: 0.9784\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0630 - acc: 0.9822\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0524 - acc: 0.9854\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0481 - acc: 0.9867\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0367 - acc: 0.9895\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0355 - acc: 0.9899\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0298 - acc: 0.9918\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0287 - acc: 0.9918\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0241 - acc: 0.9929\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0221 - acc: 0.9937\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0201 - acc: 0.9940\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0196 - acc: 0.9945\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0187 - acc: 0.9947\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0168 - acc: 0.9950\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0159 - acc: 0.9955\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0147 - acc: 0.9956\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0130 - acc: 0.9961\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0131 - acc: 0.9958\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0110 - acc: 0.9966\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0123 - acc: 0.9962\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0105 - acc: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x792b4d3cd180>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_32, y_train, batch_size= 32 , epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6fUW2Z4Xhnl",
    "outputId": "784f4237-ec7b-45c6-ae86-2a48b502fb0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 9ms/step - loss: 0.0398 - acc: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.039761289954185486, 0.9940000176429749]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_32, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl1CQgZrmkN1"
   },
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 6: بازشناسی از روی تصویر کاغذ </div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "B7gI12NDEedK"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "N_B1QY40GNQk"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\" , metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2FtSPc4GjNC",
    "outputId": "ae2360a7-b28f-405a-ba33-33631d8f9dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 1.4544 - acc: 0.4654\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8714 - acc: 0.7027\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6820 - acc: 0.7772\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5763 - acc: 0.8149\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5101 - acc: 0.8385\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4586 - acc: 0.8561\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4264 - acc: 0.8672\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3953 - acc: 0.8788\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3770 - acc: 0.8852\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3539 - acc: 0.8927\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3354 - acc: 0.8985\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3200 - acc: 0.9022\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3111 - acc: 0.9054\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2929 - acc: 0.9118\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2865 - acc: 0.9132\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2738 - acc: 0.9177\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2678 - acc: 0.9200\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2578 - acc: 0.9229\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2499 - acc: 0.9256\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2409 - acc: 0.9268\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2299 - acc: 0.9309\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2253 - acc: 0.9330\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2187 - acc: 0.9349\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2146 - acc: 0.9348\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2074 - acc: 0.9386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7982b33e1f30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_32, y_train, batch_size= 32 , epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "x4htj42DG7g_"
   },
   "outputs": [],
   "source": [
    "digit_lists = []\n",
    "\n",
    "# Read the input image (make sure it's a binary image)\n",
    "\n",
    "image = cv2.imread('english-digits.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#plt.imshow(image, cmap = 'gray')\n",
    "\n",
    "# Apply thresholding to create a binary image\n",
    "_, binary_image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
    "#plt.imshow(binary_image, cmap = 'gray')\n",
    "\n",
    "binary_image = 255-binary_image\n",
    "#plt.imshow(binary_image, cmap = 'gray')\n",
    "\n",
    "# Use connectedComponentsWithStats to obtain labels and bounding boxes\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
    "\n",
    "# Iterate through each connected component\n",
    "for label in range(1, num_labels):\n",
    "    # Get the bounding box of the current connected component\n",
    "    x, y, w, h = stats[label][:4]\n",
    "\n",
    "    # Crop the connected component using the bounding box\n",
    "    connected_component = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Display or save the cropped connected component\n",
    "    digit_lists.append(connected_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "wgy9KyzSuULQ",
    "outputId": "7210ab5d-94af-4146-93fb-36d9409d3ef5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "      .ndarray_repr .ndarray_raw_data {\n",
       "        display: none;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_raw_data {\n",
       "        display: block;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_image_preview {\n",
       "        display: none;\n",
       "      }\n",
       "      </style>\n",
       "      <div id=\"id-80a6bdd6-64ad-460d-b0ce-2771239dded8\" class=\"ndarray_repr\"><pre>ndarray (32, 19) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAAgCAAAAADV1RwTAAAB9ElEQVR4nCXM3U4TQRQA4HPOnNmd6R+0YLEiBJUEiRqjJsYn9yGMXnghBISS0tRA2wVqu9tld+YcL/we4MNvVvO8XOXT2u0OPCcKwGl8mNwuy8diLbP1XscaULbZ+cUcmm6nmt1CfeCAhIurn1O383y7JePzaZ7HLc88uxy1jg777QQ6/mK4KD702nw/K/bfHLJ4oZa/HeOBa/Jw3nnVtyCl+vRt/PpbP3+hu9DuegIkCeC7bTu6nNKk6va9iKAEdd0NzoYTzrDbo0pFFUVTp+nfKUXbaWJEDGRiKUYa1R0lqbNA1ggaqY3jGO6JRESIBAGEmptNpJxjXdUIGhIVsK7dcBKonJxlKQUnWrlYDTbhgeixDqGOogigCpwSRIqKKgKAACCYtK1Gtt5bIkJUUNG0wxDZc8OCChIAqNoWITJTajQiJICoQh6QmCEx/zciFbQKzISWjTGqAAgKpGiolFBFlShsNTh3H/Me+fV8hQYTiXUgWOfReUry+dqg2garJJDNVs0ubVBRglQVSgBXj8eLTp/2N4qbJWFVPoLl7HQkgwHtDeLwOqSk7M3y7Ndy72iHX5RpfhJ6RGTzP99vdj+92+KXm/7H5eqpB2Oy0Wk4Pj5o4JkshidXS4VEFsX2+9cfQbk2jX5hHuq71D5xz472QeEf4ZUREqA6y6IAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[202, 207, 206, 195, 184, 176, 164, 153, 131, 126, 134, 161, 186,\n",
       "        195, 199, 205, 204, 204, 204],\n",
       "       [209, 206, 190, 163, 140, 127, 119, 112, 102,  93,  91, 113, 152,\n",
       "        181, 195, 204, 207, 207, 206],\n",
       "       [214, 190, 152, 116,  96,  96, 107, 115, 125, 119,  98,  90, 113,\n",
       "        147, 179, 203, 207, 209, 207],\n",
       "       [204, 157, 105,  83,  91, 114, 142, 162, 174, 172, 143, 105,  91,\n",
       "        102, 136, 176, 195, 204, 208],\n",
       "       [183, 122,  74,  86, 130, 166, 188, 201, 207, 207, 186, 152, 116,\n",
       "         82,  87, 126, 175, 193, 206],\n",
       "       [166, 101,  64, 104, 173, 209, 213, 211, 220, 218, 209, 198, 161,\n",
       "         93,  64,  88, 158, 183, 204],\n",
       "       [132,  81,  78, 139, 195, 214, 214, 209, 212, 211, 218, 216, 205,\n",
       "        158,  84,  51,  87, 141, 197],\n",
       "       [114,  77,  91, 156, 204, 216, 214, 210, 214, 209, 214, 216, 214,\n",
       "        175,  97,  56,  56, 106, 175],\n",
       "       [ 87,  71, 108, 178, 213, 214, 212, 208, 215, 207, 210, 215, 222,\n",
       "        192, 112,  60,  37,  72, 148],\n",
       "       [ 68,  69, 125, 196, 215, 209, 208, 206, 214, 206, 211, 213, 221,\n",
       "        199, 120,  59,  44,  58, 126],\n",
       "       [ 65,  74, 139, 207, 216, 206, 209, 207, 210, 208, 214, 210, 213,\n",
       "        197, 123,  57,  54,  52, 108],\n",
       "       [ 71,  81, 147, 212, 216, 208, 214, 210, 208, 209, 217, 208, 208,\n",
       "        200, 131,  61,  51,  48,  91],\n",
       "       [ 73,  79, 145, 210, 214, 210, 216, 208, 209, 209, 217, 206, 210,\n",
       "        211, 147,  72,  52,  50,  80],\n",
       "       [ 70,  74, 139, 205, 211, 210, 215, 204, 210, 209, 215, 206, 215,\n",
       "        223, 160,  82,  60,  58,  76],\n",
       "       [ 62,  47, 100, 186, 218, 212, 211, 212, 208, 208, 209, 214, 212,\n",
       "        217, 185,  98,  60,  42,  78],\n",
       "       [ 55,  42,  96, 182, 213, 209, 209, 211, 209, 208, 209, 213, 211,\n",
       "        217, 189, 105,  62,  42,  75],\n",
       "       [ 52,  41,  97, 181, 211, 207, 209, 211, 210, 208, 209, 213, 209,\n",
       "        218, 195, 118,  67,  41,  72],\n",
       "       [ 57,  50, 106, 186, 213, 209, 211, 212, 212, 209, 209, 212, 207,\n",
       "        217, 202, 132,  71,  41,  69],\n",
       "       [ 66,  61, 116, 191, 213, 208, 209, 210, 212, 209, 209, 212, 206,\n",
       "        216, 207, 144,  73,  42,  70],\n",
       "       [ 70,  68, 123, 194, 212, 205, 206, 206, 212, 209, 210, 213, 205,\n",
       "        214, 209, 153,  73,  43,  72],\n",
       "       [ 74,  74, 129, 197, 212, 205, 207, 207, 212, 209, 212, 215, 204,\n",
       "        212, 210, 158,  72,  43,  76],\n",
       "       [ 76,  77, 134, 201, 215, 208, 211, 210, 211, 209, 212, 216, 204,\n",
       "        211, 210, 160,  71,  44,  79],\n",
       "       [ 68,  75, 130, 195, 212, 207, 209, 207, 209, 213, 217, 215, 200,\n",
       "        219, 218, 143,  68,  33,  97],\n",
       "       [ 77,  66, 110, 183, 213, 210, 210, 213, 207, 210, 212, 211, 202,\n",
       "        219, 209, 132,  65,  41, 106],\n",
       "       [ 83,  55,  90, 174, 216, 211, 209, 218, 217, 214, 211, 209, 208,\n",
       "        219, 190, 111,  53,  52, 123],\n",
       "       [ 98,  57,  80, 166, 216, 209, 203, 212, 218, 212, 207, 209, 216,\n",
       "        214, 161,  82,  38,  66, 145],\n",
       "       [128,  72,  70, 142, 203, 211, 204, 206, 210, 205, 207, 214, 220,\n",
       "        195, 120,  51,  36,  91, 170],\n",
       "       [157,  97,  67, 108, 173, 207, 211, 208, 209, 209, 216, 217, 207,\n",
       "        156,  77,  38,  65, 130, 193],\n",
       "       [190, 149, 104,  97, 131, 169, 187, 189, 191, 193, 198, 187, 161,\n",
       "        104,  53,  65, 116, 175, 212],\n",
       "       [224, 206, 158, 107,  96, 119, 143, 152, 152, 155, 158, 139, 108,\n",
       "         63,  49, 106, 157, 207, 222],\n",
       "       [217, 215, 200, 166, 124,  91,  78,  77,  77,  83,  81,  66,  56,\n",
       "         76, 123, 163, 213, 213, 212],\n",
       "       [212, 215, 210, 188, 156, 127, 111, 106,  88,  95, 100, 102, 110,\n",
       "        136, 175, 205, 213, 212, 212]], dtype=uint8)</pre></div><script>\n",
       "      (() => {\n",
       "      const titles = ['show data', 'hide data'];\n",
       "      let index = 0\n",
       "      document.querySelector('#id-80a6bdd6-64ad-460d-b0ce-2771239dded8 button').onclick = (e) => {\n",
       "        document.querySelector('#id-80a6bdd6-64ad-460d-b0ce-2771239dded8').classList.toggle('show_array');\n",
       "        index = (++index) % 2;\n",
       "        document.querySelector('#id-80a6bdd6-64ad-460d-b0ce-2771239dded8 button').textContent = titles[index];\n",
       "        e.preventDefault();\n",
       "        e.stopPropagation();\n",
       "      }\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "array([[202, 207, 206, 195, 184, 176, 164, 153, 131, 126, 134, 161, 186,\n",
       "        195, 199, 205, 204, 204, 204],\n",
       "       [209, 206, 190, 163, 140, 127, 119, 112, 102,  93,  91, 113, 152,\n",
       "        181, 195, 204, 207, 207, 206],\n",
       "       [214, 190, 152, 116,  96,  96, 107, 115, 125, 119,  98,  90, 113,\n",
       "        147, 179, 203, 207, 209, 207],\n",
       "       [204, 157, 105,  83,  91, 114, 142, 162, 174, 172, 143, 105,  91,\n",
       "        102, 136, 176, 195, 204, 208],\n",
       "       [183, 122,  74,  86, 130, 166, 188, 201, 207, 207, 186, 152, 116,\n",
       "         82,  87, 126, 175, 193, 206],\n",
       "       [166, 101,  64, 104, 173, 209, 213, 211, 220, 218, 209, 198, 161,\n",
       "         93,  64,  88, 158, 183, 204],\n",
       "       [132,  81,  78, 139, 195, 214, 214, 209, 212, 211, 218, 216, 205,\n",
       "        158,  84,  51,  87, 141, 197],\n",
       "       [114,  77,  91, 156, 204, 216, 214, 210, 214, 209, 214, 216, 214,\n",
       "        175,  97,  56,  56, 106, 175],\n",
       "       [ 87,  71, 108, 178, 213, 214, 212, 208, 215, 207, 210, 215, 222,\n",
       "        192, 112,  60,  37,  72, 148],\n",
       "       [ 68,  69, 125, 196, 215, 209, 208, 206, 214, 206, 211, 213, 221,\n",
       "        199, 120,  59,  44,  58, 126],\n",
       "       [ 65,  74, 139, 207, 216, 206, 209, 207, 210, 208, 214, 210, 213,\n",
       "        197, 123,  57,  54,  52, 108],\n",
       "       [ 71,  81, 147, 212, 216, 208, 214, 210, 208, 209, 217, 208, 208,\n",
       "        200, 131,  61,  51,  48,  91],\n",
       "       [ 73,  79, 145, 210, 214, 210, 216, 208, 209, 209, 217, 206, 210,\n",
       "        211, 147,  72,  52,  50,  80],\n",
       "       [ 70,  74, 139, 205, 211, 210, 215, 204, 210, 209, 215, 206, 215,\n",
       "        223, 160,  82,  60,  58,  76],\n",
       "       [ 62,  47, 100, 186, 218, 212, 211, 212, 208, 208, 209, 214, 212,\n",
       "        217, 185,  98,  60,  42,  78],\n",
       "       [ 55,  42,  96, 182, 213, 209, 209, 211, 209, 208, 209, 213, 211,\n",
       "        217, 189, 105,  62,  42,  75],\n",
       "       [ 52,  41,  97, 181, 211, 207, 209, 211, 210, 208, 209, 213, 209,\n",
       "        218, 195, 118,  67,  41,  72],\n",
       "       [ 57,  50, 106, 186, 213, 209, 211, 212, 212, 209, 209, 212, 207,\n",
       "        217, 202, 132,  71,  41,  69],\n",
       "       [ 66,  61, 116, 191, 213, 208, 209, 210, 212, 209, 209, 212, 206,\n",
       "        216, 207, 144,  73,  42,  70],\n",
       "       [ 70,  68, 123, 194, 212, 205, 206, 206, 212, 209, 210, 213, 205,\n",
       "        214, 209, 153,  73,  43,  72],\n",
       "       [ 74,  74, 129, 197, 212, 205, 207, 207, 212, 209, 212, 215, 204,\n",
       "        212, 210, 158,  72,  43,  76],\n",
       "       [ 76,  77, 134, 201, 215, 208, 211, 210, 211, 209, 212, 216, 204,\n",
       "        211, 210, 160,  71,  44,  79],\n",
       "       [ 68,  75, 130, 195, 212, 207, 209, 207, 209, 213, 217, 215, 200,\n",
       "        219, 218, 143,  68,  33,  97],\n",
       "       [ 77,  66, 110, 183, 213, 210, 210, 213, 207, 210, 212, 211, 202,\n",
       "        219, 209, 132,  65,  41, 106],\n",
       "       [ 83,  55,  90, 174, 216, 211, 209, 218, 217, 214, 211, 209, 208,\n",
       "        219, 190, 111,  53,  52, 123],\n",
       "       [ 98,  57,  80, 166, 216, 209, 203, 212, 218, 212, 207, 209, 216,\n",
       "        214, 161,  82,  38,  66, 145],\n",
       "       [128,  72,  70, 142, 203, 211, 204, 206, 210, 205, 207, 214, 220,\n",
       "        195, 120,  51,  36,  91, 170],\n",
       "       [157,  97,  67, 108, 173, 207, 211, 208, 209, 209, 216, 217, 207,\n",
       "        156,  77,  38,  65, 130, 193],\n",
       "       [190, 149, 104,  97, 131, 169, 187, 189, 191, 193, 198, 187, 161,\n",
       "        104,  53,  65, 116, 175, 212],\n",
       "       [224, 206, 158, 107,  96, 119, 143, 152, 152, 155, 158, 139, 108,\n",
       "         63,  49, 106, 157, 207, 222],\n",
       "       [217, 215, 200, 166, 124,  91,  78,  77,  77,  83,  81,  66,  56,\n",
       "         76, 123, 163, 213, 213, 212],\n",
       "       [212, 215, 210, 188, 156, 127, 111, 106,  88,  95, 100, 102, 110,\n",
       "        136, 175, 205, 213, 212, 212]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Q9kGo_zIyYqH"
   },
   "outputs": [],
   "source": [
    "first=digit_lists[0].reshape(-1,32,19,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wARFOf6yJG0",
    "outputId": "011d7e5b-7368-46d7-e961-db055e48c704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "smYfxPqkmkN1",
    "outputId": "5e914167-69ca-4632-f083-7f8b11a1f5b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "      .ndarray_repr .ndarray_raw_data {\n",
       "        display: none;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_raw_data {\n",
       "        display: block;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_image_preview {\n",
       "        display: none;\n",
       "      }\n",
       "      </style>\n",
       "      <div id=\"id-a2d4dc43-0936-4871-8d42-3f91d9010aa5\" class=\"ndarray_repr\"><pre>ndarray (41, 26) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABoAAAApCAAAAAAOz2YRAAADKklEQVR4nE2S3U8bVxDFZ+6du3d3bWOMMTUEcAMERBullfKQ8pCHVuof29f+AVGfqjZqSVOShoIIgth8E9v12rt7v6YPmKbnaaSfzpw50uArzEZX/WxkudBRbXZ+vpGGYL0kJCxu/z49z3IbnKO40lxdby+kuvRS4C/dw92h0QpRWjMeGT1b+36jIyZBUvfV20Gts9SQUkfjm/Nu7/1ouPNtR08s7b853/x8Y6mOHEWuzK7fH/T2MFFtZel03H66thgr8AKUnnuw9qT/49nL6k5VUJZubawkeS48og9SpZ3l9Ie9d48SpHaxvswTQBYQWxscAy9/p/ZXVx1tj9sw1QRQCQCYbXZcbIG2x417JJm9B8TLc9eqgqRaHJspiowNQkDYfenWWtoLj5anKh3oBIfdgx4vL0qmwB7vN4pIlVeH3evZ9U7VMrEI4b+s8uPV8dFl44svm4EFBSn8FFk7vPhwPoDVpw+dkUhYhKLis+BHEzMa9K/syuYzGhWqBoQCqmW3m7u8OGCBXuU3+62FOTNGQoEi+7CfQQiQpCrY4bC3/GRD50wCWSZzS0aRaqYJm37v8rR7lW8llgBRtytrLCm2sULpbi9/fvNrqbaIAHGS1mfQs87ZsU51Yy5+8Xa+/hkBQMkCpfVGO29tgeHhTv+3Pxa0AOAqeceSqHAyTZWk7MHjWu9oSBzAgcCAIigO3jEAwtbszF87Aj6JGQBRCLRcN/5UAAAgADBwCFMWqF1GRzQlAIweGBABIBJzpjUgvgfAUxM4JbhIjPgUxPeDBXdb2Or/zxBSCEQE6cc3YVC7y+L7twFGhMiaTGSJYGBrnQuMYgLEAcFgemsnWCcNhoABgFkbLwkx5uHFQLXmKfhwVwuAQCU4cZR+PO7PrC3SpW/QXRtwgtha5vz0aLK50aQDkQIIAGCOuBxTwub17yfR6kqVuqHRESAQgIUHlcDFyYtDv/moqSicYUE61kpi6YGG1++Oj+z288dpoPSfwZ6u1GsVTfXS+8HJWQatr58t5AZ/ev3njbfWMUMUKVc4FaXPv6nkrKgdrey6Ii+ND6xjiTKOvlqssBT8L3ClvR4EcBBqAAAAAElFTkSuQmCC\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[207, 208, 196, ..., 205, 209, 210],\n",
       "       [208, 200, 177, ..., 202, 208, 211],\n",
       "       [200, 172, 135, ..., 204, 202, 205],\n",
       "       ...,\n",
       "       [127,  77,  75, ..., 216, 207, 203],\n",
       "       [192, 145,  99, ..., 201, 200, 205],\n",
       "       [216, 198, 174, ..., 204, 206, 205]], dtype=uint8)</pre></div><script>\n",
       "      (() => {\n",
       "      const titles = ['show data', 'hide data'];\n",
       "      let index = 0\n",
       "      document.querySelector('#id-a2d4dc43-0936-4871-8d42-3f91d9010aa5 button').onclick = (e) => {\n",
       "        document.querySelector('#id-a2d4dc43-0936-4871-8d42-3f91d9010aa5').classList.toggle('show_array');\n",
       "        index = (++index) % 2;\n",
       "        document.querySelector('#id-a2d4dc43-0936-4871-8d42-3f91d9010aa5 button').textContent = titles[index];\n",
       "        e.preventDefault();\n",
       "        e.stopPropagation();\n",
       "      }\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "array([[207, 208, 196, ..., 205, 209, 210],\n",
       "       [208, 200, 177, ..., 202, 208, 211],\n",
       "       [200, 172, 135, ..., 204, 202, 205],\n",
       "       ...,\n",
       "       [127,  77,  75, ..., 216, 207, 203],\n",
       "       [192, 145,  99, ..., 201, 200, 205],\n",
       "       [216, 198, 174, ..., 204, 206, 205]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcHX4-NjmkN1",
    "outputId": "1833341e-8616-41d6-f3b1-258390d80df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first=digit_lists[1].reshape(-1,41,26,1)\n",
    "model.predict(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "id": "kQlZLYR0mkN1",
    "outputId": "58f07f4b-7e73-4211-d869-aa294cd24a63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "      .ndarray_repr .ndarray_raw_data {\n",
       "        display: none;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_raw_data {\n",
       "        display: block;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_image_preview {\n",
       "        display: none;\n",
       "      }\n",
       "      </style>\n",
       "      <div id=\"id-4d28ca11-dc37-4194-81c4-1f15b0893c45\" class=\"ndarray_repr\"><pre>ndarray (42, 29) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB0AAAAqCAAAAABqhw/GAAADbElEQVR4nE2R2VMVZxDFT/fXM3N3QBBEkCBLuKFUIGpiVR5Slef8s/kXQpUmiFZCQpEFIxJvWGS5wJ07d+ZbOg8Dlv3663NOL/Tac1ATuTzPTjudsxztqdlhBGUQqwCAqVK30+me9RGL++Msmx81AYBCIKBwfrJ/eBGSqbvDOvj5Yse1RwyISQWiSPd3OoOxW9OzE5JePd3ck9FahZkIwvFg59WbQ4zNtKcTyrLKTL+42G1Mm0CAoHv+3+FR9tnql3cjC6mY6kTr6PB4tAUAjNrVwWW1/d339xqhcBzH1fEJHB30FAAErvO2+HxteeSUrKqq71UnGt1uzxoATJfvO+Heg9snzJUae+/TeKQR0syVzlHWtzYYNsTsHUdGEnGZRelMNHyv0e+zFoAHEWkgUkQAIMTNR98sVkgTq2SCc77wHBkjAYBAvnVjVWejggiGVdVn3cuZIWUAopURX4UH4bpipFfUaphSizqRC0TQ6wbXS+OxFgcAjMyrdWQUUKiqhvS8GB6vKwCwelcUgeEUKO9z/NZOTSXX+yasYHgLBVQVg7d7lcUJLrVgkIEPrKVU/9zN7i8lmZTUOiV4jXDt/PtBfWHS9UoaIlEXRDQJzqJ+8sPf5/OPTB5nREQCH0CkQdmjwgdbO2dza7e8Rij39QoAIfTiBEcbm8djT1eT1JRTiXIIUAIVQ3j38qd0dvVhPSUJ198XFwKYqOXePN++Wni2PJwWtWBjB0CgAAgK3l3fooePl1puEHGhkQMgapUM1Pnt33ZrC0/mK1aFcm986VywMXC++PG9fPFgbqivhgY2kQGVuWRti35Zf99oP7uPK1YHY+CYAEgh2ow/bG68u724NqlOb94MBSCRcjjYWD9pPnjYjlI1H2kAICz2zYtX2cLS2niSByF7Q8tcu/f8Zb789dxd33OkAZ+WmNe/bje+Wplp+dwLrJqbZAYg++vH9ZUnk8KZZ1JV/TSXN97F7eVxCRasNoh8pKqqcjxkuv+ktVo9VoDYGH99WyODvizvfdj7i5KRUQOT1GqJgCWK48iEmklktXnUOemm/VMOqDSbMRcgEIHuNEfHadtk/fSkc9zPBzmSCJ6Dd9a64KM7j2nLk4moyP1h1vdEzma+yLNs4P7tJs8krwRbEEfxirVgDl6CK/LBwB3sn0/+D3nz4kYrVDobAAAAAElFTkSuQmCC\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[206, 203, 205, ..., 200, 202, 201],\n",
       "       [206, 203, 205, ..., 200, 201, 201],\n",
       "       [206, 207, 207, ..., 202, 203, 202],\n",
       "       ...,\n",
       "       [213, 216, 207, ...,  73,  97, 148],\n",
       "       [210, 207, 208, ...,  48,  55, 111],\n",
       "       [203, 211, 209, ..., 123, 106, 136]], dtype=uint8)</pre></div><script>\n",
       "      (() => {\n",
       "      const titles = ['show data', 'hide data'];\n",
       "      let index = 0\n",
       "      document.querySelector('#id-4d28ca11-dc37-4194-81c4-1f15b0893c45 button').onclick = (e) => {\n",
       "        document.querySelector('#id-4d28ca11-dc37-4194-81c4-1f15b0893c45').classList.toggle('show_array');\n",
       "        index = (++index) % 2;\n",
       "        document.querySelector('#id-4d28ca11-dc37-4194-81c4-1f15b0893c45 button').textContent = titles[index];\n",
       "        e.preventDefault();\n",
       "        e.stopPropagation();\n",
       "      }\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "array([[206, 203, 205, ..., 200, 202, 201],\n",
       "       [206, 203, 205, ..., 200, 201, 201],\n",
       "       [206, 207, 207, ..., 202, 203, 202],\n",
       "       ...,\n",
       "       [213, 216, 207, ...,  73,  97, 148],\n",
       "       [210, 207, 208, ...,  48,  55, 111],\n",
       "       [203, 211, 209, ..., 123, 106, 136]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_lists[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ef650lKeJt51",
    "outputId": "447648a5-fe70-44f5-ba2d-66a4f047649f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first=digit_lists[2].reshape(-1,42,29,1)\n",
    "model.predict(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "TZyuIZAWJzP2",
    "outputId": "0c71eb53-3fba-40b0-887e-877c67e4fb0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "      .ndarray_repr .ndarray_raw_data {\n",
       "        display: none;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_raw_data {\n",
       "        display: block;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_image_preview {\n",
       "        display: none;\n",
       "      }\n",
       "      </style>\n",
       "      <div id=\"id-f5228a25-9810-4401-aad4-c26cdc7bf1be\" class=\"ndarray_repr\"><pre>ndarray (50, 34) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAyCAAAAAAc+laFAAADtUlEQVR4nGVUy5LbNhDsHgxJSdyVtOuN7dySyiU5pfIn+ef8QXLKJQ/nkIe9tlZLkRQJTOdA2es4KFThgEZPzxS6+cM0jD/+dP3tdyDNjAwQgIDLSVPjiDI+vIEgScInSxbGKExeL4/+D4ErEHNBvU0gyacbXorJmM2UT8dTSmZG4xMEEkBamsRU2XkwM/svywXiCXM3sK4S8YkOBiADzZp8uD/NOWvpKD5VS1dpVer1zX6heK+YKAKgzORoHrt+tsoCIPhUKy4PwhUPh6nZbatC0JaRXiDkBdK9fki7F7eeRYLLNABABIKQPKZDh9V1S5I0ku/1EhCK5CaeZ9I8bFH6JIYkFAWuklO7aioKEMT/YATQHENu1ru2YYHw8exEkGTQ+8M9X37z+bg2qtBVILMyKzVQAPTs+TG1t9ebUvcGcxczlZWkvBAJPtxXd3dtQqageRr7TWMBV84ERYD+2K2f3TZCIaHSv3l7c7e1AqN06dHfdu1q43BlJmad3nbpyhVmohkBhd2/OZ5yOQvJoJi6t28OI5Pi8tkB2aHvBzGXnJDnXErE0IczJClUcpb3q7rabCJllUJv991QxlJZhAAiItyrTdPOcxMoQYRbd+7lUmTGuz+O6/3q5NY2lkcamNxLoU3jwcaHx+5P9Z0/21fymlfba88RNubcH/54/fP2VdUN04Cqaj97uQl4iqpC/+6x79499P35eH88dZbXV5t9e/P8xZ7nyvvpb3t1+Oc4jEOm18F2+3JfX+/9ut1t2yrm8MeHv37F4+R2td/trlfvfv9l9/U3e3fUXllkNidPzWT1pr1drbc3m5X9dqzqmy+f5cJOkyLM4dsXcXVzvbupvW0yNew5dUcbVQessgjO/n2p1+sKERZ9JGBVH159tWsKjcgEUPnzTGIqJVaSZHWbyjTlJEEEAMG8TihZVuUAxPVNHWM/X/6oAMCGOeeAeSUBEdV2w/40wQQsGw7QoChyEBFp1XLoZoMELttQAiQkJ0ggbdCfJhieWFRotOSABNKs0dDPQhgugj3Z4jAitJhW85QlXRoibI4AAMUsIUmbL67Sw5FRXQI0stGMUERAksC0v+LYnz+yrS39RykAFDK/u7XTQ7+EC0nCSkQJLRaHYOlq5+fjQH2AeMZib4ogAFpbz8PIeB9X9Ci85DGXiCqrehrGp5CgGwkFSZhBIaipNQ76CJKWaBISyYDEOsU0hT7kovt7uClLEgzVuZ/Pd4+kAqDcykKCfJFj69vbFtNIEhSJfwEMz1y57fmLgwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[195, 189, 180, ..., 198, 198, 199],\n",
       "       [194, 196, 184, ..., 198, 198, 198],\n",
       "       [192, 198, 185, ..., 198, 198, 198],\n",
       "       ...,\n",
       "       [194, 195, 195, ..., 197, 197, 199],\n",
       "       [198, 197, 197, ..., 196, 197, 198],\n",
       "       [200, 197, 197, ..., 197, 198, 198]], dtype=uint8)</pre></div><script>\n",
       "      (() => {\n",
       "      const titles = ['show data', 'hide data'];\n",
       "      let index = 0\n",
       "      document.querySelector('#id-f5228a25-9810-4401-aad4-c26cdc7bf1be button').onclick = (e) => {\n",
       "        document.querySelector('#id-f5228a25-9810-4401-aad4-c26cdc7bf1be').classList.toggle('show_array');\n",
       "        index = (++index) % 2;\n",
       "        document.querySelector('#id-f5228a25-9810-4401-aad4-c26cdc7bf1be button').textContent = titles[index];\n",
       "        e.preventDefault();\n",
       "        e.stopPropagation();\n",
       "      }\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "array([[195, 189, 180, ..., 198, 198, 199],\n",
       "       [194, 196, 184, ..., 198, 198, 198],\n",
       "       [192, 198, 185, ..., 198, 198, 198],\n",
       "       ...,\n",
       "       [194, 195, 195, ..., 197, 197, 199],\n",
       "       [198, 197, 197, ..., 196, 197, 198],\n",
       "       [200, 197, 197, ..., 197, 198, 198]], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_lists[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKITvgaYJ7LC",
    "outputId": "e76249d0-8e47-4f86-eead-3184e821e4cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first=digit_lists[3].reshape(-1,50,34,1)\n",
    "model.predict(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyDT-sjsKCsH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
