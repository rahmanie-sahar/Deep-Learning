{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b67f16",
   "metadata": {},
   "source": [
    "# Calbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f8b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 19:15:25.442435: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-29 19:15:25.442628: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 19:15:25.444397: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 19:15:25.467175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 19:15:25.882314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089b98d",
   "metadata": {},
   "source": [
    "## Loading Fashion_Mnist Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa51d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679f7db",
   "metadata": {},
   "source": [
    "## Defining Custom Calbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2543aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"Training is started!\")\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(\"-\"*50)\n",
    "        print(\"Epoch {} is started.\".format(epoch))\n",
    "    \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        if batch%100 ==0:\n",
    "            print('Training: batch {} begins'.format(batch))\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        print(\"*\"*50)\n",
    "        t= datetime.datetime.now().time()\n",
    "        print('Evaluation begins at {}'.format(t))\n",
    "                  \n",
    "    def on_test_end(self, logs=None):\n",
    "        t= datetime.datetime.now().time()\n",
    "        print('Evaluation finishes at {}'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d276f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callback = MyCustomCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded7cbe",
   "metadata": {},
   "source": [
    "## Defining ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2660ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda385e",
   "metadata": {},
   "source": [
    "## Compiling ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59602d",
   "metadata": {},
   "source": [
    "## Fitting ANN Model with Costum Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af83e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahar/anaconda3/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is started!\n",
      "--------------------------------------------------\n",
      "Epoch 0 is started.\n",
      "Training: batch 0 begins\n",
      "Training: batch 100 begins\n",
      "Training: batch 200 begins\n",
      "Training: batch 300 begins\n",
      "Training: batch 400 begins\n",
      "Training: batch 500 begins\n",
      "Training: batch 600 begins\n",
      "Training: batch 700 begins\n",
      "Training: batch 800 begins\n",
      "Training: batch 900 begins\n",
      "Training: batch 1000 begins\n",
      "Training: batch 1100 begins\n",
      "Training: batch 1200 begins\n",
      "Training: batch 1300 begins\n",
      "Training: batch 1400 begins\n",
      "**************************************************\n",
      "Evaluation begins at 18:57:27.474904\n",
      "Evaluation finishes at 18:57:27.739210\n",
      "--------------------------------------------------\n",
      "Epoch 1 is started.\n",
      "Training: batch 0 begins\n",
      "Training: batch 100 begins\n",
      "Training: batch 200 begins\n",
      "Training: batch 300 begins\n",
      "Training: batch 400 begins\n",
      "Training: batch 500 begins\n",
      "Training: batch 600 begins\n",
      "Training: batch 700 begins\n",
      "Training: batch 800 begins\n",
      "Training: batch 900 begins\n",
      "Training: batch 1000 begins\n",
      "Training: batch 1100 begins\n",
      "Training: batch 1200 begins\n",
      "Training: batch 1300 begins\n",
      "Training: batch 1400 begins\n",
      "**************************************************\n",
      "Evaluation begins at 18:57:30.543434\n",
      "Evaluation finishes at 18:57:30.818776\n",
      "--------------------------------------------------\n",
      "Epoch 2 is started.\n",
      "Training: batch 0 begins\n",
      "Training: batch 100 begins\n",
      "Training: batch 200 begins\n",
      "Training: batch 300 begins\n",
      "Training: batch 400 begins\n",
      "Training: batch 500 begins\n",
      "Training: batch 600 begins\n",
      "Training: batch 700 begins\n",
      "Training: batch 800 begins\n",
      "Training: batch 900 begins\n",
      "Training: batch 1000 begins\n",
      "Training: batch 1100 begins\n",
      "Training: batch 1200 begins\n",
      "Training: batch 1300 begins\n",
      "Training: batch 1400 begins\n",
      "**************************************************\n",
      "Evaluation begins at 18:57:33.571575\n",
      "Evaluation finishes at 18:57:33.919271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c0908171090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=3,validation_split=0.2,callbacks=[my_callback], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439872d",
   "metadata": {},
   "source": [
    "## Defining Stop Training Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4558e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(logs)\n",
    "        if(logs.get('accuracy')>0.6):\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd442219",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5259f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1839/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.5844{'accuracy': 0.8298666477203369, 'loss': 0.47259077429771423}\n",
      "\n",
      "Reached 60% accuracy so cancelling training!\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7920 - loss: 0.5822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c09047a8410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399e955",
   "metadata": {},
   "source": [
    "## Defingin Tensorboard CallBack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae48a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12fa5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb8f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3b9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logDir:  ./logs/mlp500/20240529-190236\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2960 - val_accuracy: 0.8756 - val_loss: 0.3462\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2899 - val_accuracy: 0.8779 - val_loss: 0.3399\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.2756 - val_accuracy: 0.8818 - val_loss: 0.3336\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2611 - val_accuracy: 0.8846 - val_loss: 0.3370\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.2637 - val_accuracy: 0.8803 - val_loss: 0.3249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c08c84a91d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logDir = \"./logs/mlp500/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(\"logDir: \", logDir)\n",
    "tensorboard_callback = TensorBoard(logDir)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e86bc",
   "metadata": {},
   "source": [
    "## Defining Checkpoint Calback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24d275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a447e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf038ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahar/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e918e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \".weights.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)# Create a callback that saves the model's weights\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                   save_weights_only=True,\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a949b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3744 - loss: 1.7655   \n",
      "Epoch 1: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4391 - loss: 1.5977 - val_accuracy: 0.7370 - val_loss: 0.7450\n",
      "Epoch 2/10\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.7442\n",
      "Epoch 2: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.7427 - val_accuracy: 0.7520 - val_loss: 0.6771\n",
      "Epoch 3/10\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.4834\n",
      "Epoch 3: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.6251 - val_accuracy: 0.7720 - val_loss: 0.6604\n",
      "Epoch 4/10\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7500 - loss: 0.6416\n",
      "Epoch 4: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.5406 - val_accuracy: 0.7750 - val_loss: 0.6132\n",
      "Epoch 5/10\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8750 - loss: 0.3918\n",
      "Epoch 5: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.4778 - val_accuracy: 0.7750 - val_loss: 0.6184\n",
      "Epoch 6/10\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9062 - loss: 0.2095\n",
      "Epoch 6: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: 0.4315 - val_accuracy: 0.7810 - val_loss: 0.5992\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.3899 \n",
      "Epoch 7: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8760 - loss: 0.3902 - val_accuracy: 0.7910 - val_loss: 0.5792\n",
      "Epoch 8/10\n",
      "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.3808 \n",
      "Epoch 8: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8780 - loss: 0.3782 - val_accuracy: 0.7860 - val_loss: 0.5973\n",
      "Epoch 9/10\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8125 - loss: 0.4038\n",
      "Epoch 9: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3751 - val_accuracy: 0.8040 - val_loss: 0.5699\n",
      "Epoch 10/10\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.2097\n",
      "Epoch 10: saving model to .weights.h5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.3122 - val_accuracy: 0.7840 - val_loss: 0.5878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d5153d63850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # Pass callback to training\n",
    "# This may generate warnings related to saving the state of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab774bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model, accuracy:  1.80%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "model = create_model()# Evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10a24d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, accuracy: 78.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahar/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)# Re-evaluate the model\n",
    "loss,acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
